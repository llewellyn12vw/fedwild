================================================================================
FEDERATED LEARNING EXPERIMENT SUMMARY
================================================================================

EXPERIMENT INFORMATION:
----------------------------------------
Name: leopardEx1
Timestamp: 2025-07-27T14:12:44.502150
Total Rounds: 50

DATASET CONFIGURATION:
----------------------------------------
Dataset Type: leopard
Client Datasets: 0,1,3
Metadata File: /home/wellvw12/fedwild/federated_clients_enhanced/metadata.csv
Use All Training Data: False

MODEL CONFIGURATION:
----------------------------------------
Model Architecture: resnet18_ft_net
Model Name: federated_model
Drop Rate: 0.03
Stride: 2

TRAINING CONFIGURATION:
----------------------------------------
Learning Rate: 0.001
Batch Size: 32
Local Epochs: 1
Number of Clients: 2
Cosine Annealing: False

OPTIMIZATION TECHNIQUES:
----------------------------------------
Cosine Distance Weighting (CDW): True
Knowledge Distillation (KD): False

FEDGKD CONFIGURATION:
----------------------------------------
FedGKD Enabled: True
  - Buffer Length: 5
  - Distillation Coefficient: 0.8
  - Temperature: 3.0
  - Average Parameters: True
  - Start Round: 5
  - Strategy: FedGKD (simple averaging)

DATA AUGMENTATION:
----------------------------------------
Random Erasing Probability: 0
Color Jitter: False

SYSTEM INFORMATION:
----------------------------------------
Platform: Linux-5.10.0-35-cloud-amd64-x86_64-with-glibc2.31
Python Version: 3.10.15
PyTorch Version: 2.7.1+cu126
CUDA Available: True
CUDA Version: 12.6
GPU Count: 1

================================================================================
Configuration saved at: 2025-07-27T14:12:44.504653
================================================================================
