================================================================================
FEDERATED LEARNING EXPERIMENT SUMMARY
================================================================================

EXPERIMENT INFORMATION:
----------------------------------------
Name: macaque/ExFEDGDK/8
Timestamp: 2025-07-27T18:42:33.204107
Total Rounds: 100

DATASET CONFIGURATION:
----------------------------------------
Dataset Type: macaque
Client Datasets: 0,1,2
Metadata File: /home/wellvw12/fedwild/federated_clients_enhanced/metadata.csv
Use All Training Data: False
Image Size: 128x128

MODEL CONFIGURATION:
----------------------------------------
Model Architecture: resnet18_ft_net
Model Name: federated_model
Drop Rate: 0.03
Stride: 2

TRAINING CONFIGURATION:
----------------------------------------
Learning Rate: 0.001
Batch Size: 32
Local Epochs: 2
Number of Clients: 3
Cosine Annealing: False

OPTIMIZATION TECHNIQUES:
----------------------------------------
Cosine Distance Weighting (CDW): True
Knowledge Distillation (KD): False

FEDGKD CONFIGURATION:
----------------------------------------
FedGKD Enabled: True
  - Buffer Length: 10
  - Distillation Coefficient: 0.2
  - Temperature: 2.0
  - Average Parameters: True
  - Start Round: 20
  - Strategy: FedGKD (simple averaging)

DATA AUGMENTATION:
----------------------------------------
Random Erasing Probability: 0
Color Jitter: False

SYSTEM INFORMATION:
----------------------------------------
Platform: Linux-5.10.0-35-cloud-amd64-x86_64-with-glibc2.31
Python Version: 3.10.15
PyTorch Version: 2.7.1+cu126
CUDA Available: True
CUDA Version: 12.6
GPU Count: 1

================================================================================
Configuration saved at: 2025-07-27T18:42:33.206702
================================================================================
